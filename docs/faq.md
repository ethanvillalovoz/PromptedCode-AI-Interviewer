# ‚ùì FAQ

**Q: Why use Llama 3?**  
A: Llama 3 provides high-quality, diverse coding challenges and is open for research and commercial use.

---

**Q: Can I use my own LLM?**  
A: Yes! Swap out the model in `ai_generator.py` for your preferred Hugging Face model.

---

**Q: How do I reset my quota?**  
A: Quotas reset automatically every 24 hours.

---

**Q: Does this work on Apple Silicon (M1/M2/M3)?**  
A: Yes! Use the MPS device and float16 dtype for best performance. See the README for details.

---

**Q: How do I report a bug or request a feature?**  
A: Open an [issue](https://github.com/ethanvillalovoz/llm-coding-challenge-generator/issues) or start a [discussion](https://github.com/ethanvillalovoz/llm-coding-challenge-generator/discussions).

---

**Q: Where can I find more documentation?**  
A: See the [wiki](wiki.md), [architecture](architecture.md), and [usage guide](usage-guide.md) in the `docs/` folder.
